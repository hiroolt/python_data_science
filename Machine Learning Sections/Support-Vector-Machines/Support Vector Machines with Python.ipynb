{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___\n",
    "# Support Vector Machines with Python\n",
    "\n",
    "Welcome to the Support Vector Machines with Python Lecture Notebook! Remember to refer to the video lecture for the full background information on the code here!\n",
    "\n",
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "\n",
    "We'll use the built in breast cancer dataset from Scikit Learn. We can get with the load function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is presented in a dictionary form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['feature_names', 'target', 'data', 'target_names', 'DESCR'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can grab information and arrays out of this dictionary to set up our data frame and understanding of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer Wisconsin (Diagnostic) Database\n",
      "=============================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      "References\n",
      "----------\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cancer['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
       "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
       "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
       "       'worst concave points', 'worst symmetry', 'worst fractal dimension'], \n",
       "      dtype='<U23')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      "mean radius                569 non-null float64\n",
      "mean texture               569 non-null float64\n",
      "mean perimeter             569 non-null float64\n",
      "mean area                  569 non-null float64\n",
      "mean smoothness            569 non-null float64\n",
      "mean compactness           569 non-null float64\n",
      "mean concavity             569 non-null float64\n",
      "mean concave points        569 non-null float64\n",
      "mean symmetry              569 non-null float64\n",
      "mean fractal dimension     569 non-null float64\n",
      "radius error               569 non-null float64\n",
      "texture error              569 non-null float64\n",
      "perimeter error            569 non-null float64\n",
      "area error                 569 non-null float64\n",
      "smoothness error           569 non-null float64\n",
      "compactness error          569 non-null float64\n",
      "concavity error            569 non-null float64\n",
      "concave points error       569 non-null float64\n",
      "symmetry error             569 non-null float64\n",
      "fractal dimension error    569 non-null float64\n",
      "worst radius               569 non-null float64\n",
      "worst texture              569 non-null float64\n",
      "worst perimeter            569 non-null float64\n",
      "worst area                 569 non-null float64\n",
      "worst smoothness           569 non-null float64\n",
      "worst compactness          569 non-null float64\n",
      "worst concavity            569 non-null float64\n",
      "worst concave points       569 non-null float64\n",
      "worst symmetry             569 non-null float64\n",
      "worst fractal dimension    569 non-null float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_feat = pd.DataFrame(cancer['data'],columns=cancer['feature_names'])\n",
    "df_feat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cancer</th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17.990</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.300100</td>\n",
       "      <td>0.147100</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.71190</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20.570</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.070170</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.24160</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>19.690</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.197400</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.45040</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11.420</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.68690</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20.290</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>12.450</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.080890</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>...</td>\n",
       "      <td>15.470</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.17910</td>\n",
       "      <td>0.52490</td>\n",
       "      <td>0.53550</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>18.250</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.112700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>...</td>\n",
       "      <td>22.880</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.14420</td>\n",
       "      <td>0.25760</td>\n",
       "      <td>0.37840</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>13.710</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.093660</td>\n",
       "      <td>0.059850</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>...</td>\n",
       "      <td>17.060</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.16540</td>\n",
       "      <td>0.36820</td>\n",
       "      <td>0.26780</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>13.000</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.093530</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>...</td>\n",
       "      <td>15.490</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.17030</td>\n",
       "      <td>0.54010</td>\n",
       "      <td>0.53900</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>12.460</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.227300</td>\n",
       "      <td>0.085430</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>...</td>\n",
       "      <td>15.090</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.18530</td>\n",
       "      <td>1.05800</td>\n",
       "      <td>1.10500</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>16.020</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.032990</td>\n",
       "      <td>0.033230</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>...</td>\n",
       "      <td>19.190</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.11810</td>\n",
       "      <td>0.15510</td>\n",
       "      <td>0.14590</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>15.780</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.099540</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>...</td>\n",
       "      <td>20.420</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.13960</td>\n",
       "      <td>0.56090</td>\n",
       "      <td>0.39650</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>19.170</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.206500</td>\n",
       "      <td>0.111800</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>20.960</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.10370</td>\n",
       "      <td>0.39030</td>\n",
       "      <td>0.36390</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>15.850</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.099380</td>\n",
       "      <td>0.053640</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>...</td>\n",
       "      <td>16.840</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.19240</td>\n",
       "      <td>0.23220</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>13.730</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.212800</td>\n",
       "      <td>0.080250</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>15.030</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.16510</td>\n",
       "      <td>0.77250</td>\n",
       "      <td>0.69430</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>14.540</td>\n",
       "      <td>27.54</td>\n",
       "      <td>96.73</td>\n",
       "      <td>658.8</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.163900</td>\n",
       "      <td>0.073640</td>\n",
       "      <td>0.2303</td>\n",
       "      <td>...</td>\n",
       "      <td>17.460</td>\n",
       "      <td>37.13</td>\n",
       "      <td>124.10</td>\n",
       "      <td>943.2</td>\n",
       "      <td>0.16780</td>\n",
       "      <td>0.65770</td>\n",
       "      <td>0.70260</td>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.13410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>14.680</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.073950</td>\n",
       "      <td>0.052590</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>...</td>\n",
       "      <td>19.070</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.14640</td>\n",
       "      <td>0.18710</td>\n",
       "      <td>0.29140</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>16.130</td>\n",
       "      <td>20.68</td>\n",
       "      <td>108.10</td>\n",
       "      <td>798.8</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.20220</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>...</td>\n",
       "      <td>20.960</td>\n",
       "      <td>31.48</td>\n",
       "      <td>136.80</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.17890</td>\n",
       "      <td>0.42330</td>\n",
       "      <td>0.47840</td>\n",
       "      <td>0.20730</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.11420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>19.810</td>\n",
       "      <td>22.15</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.10270</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>...</td>\n",
       "      <td>27.320</td>\n",
       "      <td>30.88</td>\n",
       "      <td>186.80</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>0.15120</td>\n",
       "      <td>0.31500</td>\n",
       "      <td>0.53720</td>\n",
       "      <td>0.23880</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.07615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.066640</td>\n",
       "      <td>0.047810</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>...</td>\n",
       "      <td>15.110</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.17730</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.045680</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>...</td>\n",
       "      <td>14.500</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>...</td>\n",
       "      <td>10.230</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.13240</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>15.340</td>\n",
       "      <td>14.26</td>\n",
       "      <td>102.50</td>\n",
       "      <td>704.4</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.21350</td>\n",
       "      <td>0.207700</td>\n",
       "      <td>0.097560</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>...</td>\n",
       "      <td>18.070</td>\n",
       "      <td>19.08</td>\n",
       "      <td>125.10</td>\n",
       "      <td>980.9</td>\n",
       "      <td>0.13900</td>\n",
       "      <td>0.59540</td>\n",
       "      <td>0.63050</td>\n",
       "      <td>0.23930</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.09946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>21.160</td>\n",
       "      <td>23.04</td>\n",
       "      <td>137.20</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.09428</td>\n",
       "      <td>0.10220</td>\n",
       "      <td>0.109700</td>\n",
       "      <td>0.086320</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>...</td>\n",
       "      <td>29.170</td>\n",
       "      <td>35.59</td>\n",
       "      <td>188.00</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>0.14010</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.31550</td>\n",
       "      <td>0.20090</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>0.07526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>16.650</td>\n",
       "      <td>21.38</td>\n",
       "      <td>110.00</td>\n",
       "      <td>904.6</td>\n",
       "      <td>0.11210</td>\n",
       "      <td>0.14570</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>...</td>\n",
       "      <td>26.460</td>\n",
       "      <td>31.56</td>\n",
       "      <td>177.00</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>0.18050</td>\n",
       "      <td>0.35780</td>\n",
       "      <td>0.46950</td>\n",
       "      <td>0.20950</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.09564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>17.140</td>\n",
       "      <td>16.40</td>\n",
       "      <td>116.00</td>\n",
       "      <td>912.7</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.22760</td>\n",
       "      <td>0.222900</td>\n",
       "      <td>0.140100</td>\n",
       "      <td>0.3040</td>\n",
       "      <td>...</td>\n",
       "      <td>22.250</td>\n",
       "      <td>21.40</td>\n",
       "      <td>152.40</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.15450</td>\n",
       "      <td>0.39490</td>\n",
       "      <td>0.38530</td>\n",
       "      <td>0.25500</td>\n",
       "      <td>0.4066</td>\n",
       "      <td>0.10590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>14.580</td>\n",
       "      <td>21.53</td>\n",
       "      <td>97.41</td>\n",
       "      <td>644.8</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.18680</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.087830</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>...</td>\n",
       "      <td>17.620</td>\n",
       "      <td>33.21</td>\n",
       "      <td>122.40</td>\n",
       "      <td>896.9</td>\n",
       "      <td>0.15250</td>\n",
       "      <td>0.66430</td>\n",
       "      <td>0.55390</td>\n",
       "      <td>0.27010</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>0.12750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>18.610</td>\n",
       "      <td>20.25</td>\n",
       "      <td>122.10</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>0.09440</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.077310</td>\n",
       "      <td>0.1697</td>\n",
       "      <td>...</td>\n",
       "      <td>21.310</td>\n",
       "      <td>27.26</td>\n",
       "      <td>139.90</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>0.13380</td>\n",
       "      <td>0.21170</td>\n",
       "      <td>0.34460</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.07421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>15.300</td>\n",
       "      <td>25.27</td>\n",
       "      <td>102.40</td>\n",
       "      <td>732.4</td>\n",
       "      <td>0.10820</td>\n",
       "      <td>0.16970</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.087510</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>...</td>\n",
       "      <td>20.270</td>\n",
       "      <td>36.71</td>\n",
       "      <td>149.30</td>\n",
       "      <td>1269.0</td>\n",
       "      <td>0.16410</td>\n",
       "      <td>0.61100</td>\n",
       "      <td>0.63350</td>\n",
       "      <td>0.20240</td>\n",
       "      <td>0.4027</td>\n",
       "      <td>0.09876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>17.570</td>\n",
       "      <td>15.05</td>\n",
       "      <td>115.00</td>\n",
       "      <td>955.1</td>\n",
       "      <td>0.09847</td>\n",
       "      <td>0.11570</td>\n",
       "      <td>0.098750</td>\n",
       "      <td>0.079530</td>\n",
       "      <td>0.1739</td>\n",
       "      <td>...</td>\n",
       "      <td>20.010</td>\n",
       "      <td>19.52</td>\n",
       "      <td>134.90</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.28120</td>\n",
       "      <td>0.24890</td>\n",
       "      <td>0.14560</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>0.07919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>1</td>\n",
       "      <td>7.691</td>\n",
       "      <td>25.44</td>\n",
       "      <td>48.34</td>\n",
       "      <td>170.4</td>\n",
       "      <td>0.08668</td>\n",
       "      <td>0.11990</td>\n",
       "      <td>0.092520</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>0.2037</td>\n",
       "      <td>...</td>\n",
       "      <td>8.678</td>\n",
       "      <td>31.89</td>\n",
       "      <td>54.49</td>\n",
       "      <td>223.6</td>\n",
       "      <td>0.15960</td>\n",
       "      <td>0.30640</td>\n",
       "      <td>0.33930</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.10660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>1</td>\n",
       "      <td>11.540</td>\n",
       "      <td>14.44</td>\n",
       "      <td>74.65</td>\n",
       "      <td>402.9</td>\n",
       "      <td>0.09984</td>\n",
       "      <td>0.11200</td>\n",
       "      <td>0.067370</td>\n",
       "      <td>0.025940</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>...</td>\n",
       "      <td>12.260</td>\n",
       "      <td>19.68</td>\n",
       "      <td>78.78</td>\n",
       "      <td>457.8</td>\n",
       "      <td>0.13450</td>\n",
       "      <td>0.21180</td>\n",
       "      <td>0.17970</td>\n",
       "      <td>0.06918</td>\n",
       "      <td>0.2329</td>\n",
       "      <td>0.08134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>1</td>\n",
       "      <td>14.470</td>\n",
       "      <td>24.99</td>\n",
       "      <td>95.81</td>\n",
       "      <td>656.4</td>\n",
       "      <td>0.08837</td>\n",
       "      <td>0.12300</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.1872</td>\n",
       "      <td>...</td>\n",
       "      <td>16.220</td>\n",
       "      <td>31.73</td>\n",
       "      <td>113.50</td>\n",
       "      <td>808.9</td>\n",
       "      <td>0.13400</td>\n",
       "      <td>0.42020</td>\n",
       "      <td>0.40400</td>\n",
       "      <td>0.12050</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>1</td>\n",
       "      <td>14.740</td>\n",
       "      <td>25.42</td>\n",
       "      <td>94.70</td>\n",
       "      <td>668.6</td>\n",
       "      <td>0.08275</td>\n",
       "      <td>0.07214</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>0.030270</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>...</td>\n",
       "      <td>16.510</td>\n",
       "      <td>32.29</td>\n",
       "      <td>107.40</td>\n",
       "      <td>826.4</td>\n",
       "      <td>0.10600</td>\n",
       "      <td>0.13760</td>\n",
       "      <td>0.16110</td>\n",
       "      <td>0.10950</td>\n",
       "      <td>0.2722</td>\n",
       "      <td>0.06956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>1</td>\n",
       "      <td>13.210</td>\n",
       "      <td>28.06</td>\n",
       "      <td>84.88</td>\n",
       "      <td>538.4</td>\n",
       "      <td>0.08671</td>\n",
       "      <td>0.06877</td>\n",
       "      <td>0.029870</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>...</td>\n",
       "      <td>14.370</td>\n",
       "      <td>37.17</td>\n",
       "      <td>92.48</td>\n",
       "      <td>629.6</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0.13810</td>\n",
       "      <td>0.10620</td>\n",
       "      <td>0.07958</td>\n",
       "      <td>0.2473</td>\n",
       "      <td>0.06443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>1</td>\n",
       "      <td>13.870</td>\n",
       "      <td>20.70</td>\n",
       "      <td>89.77</td>\n",
       "      <td>584.8</td>\n",
       "      <td>0.09578</td>\n",
       "      <td>0.10180</td>\n",
       "      <td>0.036880</td>\n",
       "      <td>0.023690</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>...</td>\n",
       "      <td>15.050</td>\n",
       "      <td>24.75</td>\n",
       "      <td>99.17</td>\n",
       "      <td>688.6</td>\n",
       "      <td>0.12640</td>\n",
       "      <td>0.20370</td>\n",
       "      <td>0.13770</td>\n",
       "      <td>0.06845</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>0.08492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>1</td>\n",
       "      <td>13.620</td>\n",
       "      <td>23.23</td>\n",
       "      <td>87.19</td>\n",
       "      <td>573.2</td>\n",
       "      <td>0.09246</td>\n",
       "      <td>0.06747</td>\n",
       "      <td>0.029740</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>0.1664</td>\n",
       "      <td>...</td>\n",
       "      <td>15.350</td>\n",
       "      <td>29.09</td>\n",
       "      <td>97.58</td>\n",
       "      <td>729.8</td>\n",
       "      <td>0.12160</td>\n",
       "      <td>0.15170</td>\n",
       "      <td>0.10490</td>\n",
       "      <td>0.07174</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.06953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>1</td>\n",
       "      <td>10.320</td>\n",
       "      <td>16.35</td>\n",
       "      <td>65.31</td>\n",
       "      <td>324.9</td>\n",
       "      <td>0.09434</td>\n",
       "      <td>0.04994</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>...</td>\n",
       "      <td>11.250</td>\n",
       "      <td>21.77</td>\n",
       "      <td>71.12</td>\n",
       "      <td>384.9</td>\n",
       "      <td>0.12850</td>\n",
       "      <td>0.08842</td>\n",
       "      <td>0.04384</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>0.2681</td>\n",
       "      <td>0.07399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>1</td>\n",
       "      <td>10.260</td>\n",
       "      <td>16.58</td>\n",
       "      <td>65.85</td>\n",
       "      <td>320.8</td>\n",
       "      <td>0.08877</td>\n",
       "      <td>0.08066</td>\n",
       "      <td>0.043580</td>\n",
       "      <td>0.024380</td>\n",
       "      <td>0.1669</td>\n",
       "      <td>...</td>\n",
       "      <td>10.830</td>\n",
       "      <td>22.04</td>\n",
       "      <td>71.08</td>\n",
       "      <td>357.4</td>\n",
       "      <td>0.14610</td>\n",
       "      <td>0.22460</td>\n",
       "      <td>0.17830</td>\n",
       "      <td>0.08333</td>\n",
       "      <td>0.2691</td>\n",
       "      <td>0.09479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>1</td>\n",
       "      <td>9.683</td>\n",
       "      <td>19.34</td>\n",
       "      <td>61.05</td>\n",
       "      <td>285.7</td>\n",
       "      <td>0.08491</td>\n",
       "      <td>0.05030</td>\n",
       "      <td>0.023370</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>...</td>\n",
       "      <td>10.930</td>\n",
       "      <td>25.59</td>\n",
       "      <td>69.10</td>\n",
       "      <td>364.2</td>\n",
       "      <td>0.11990</td>\n",
       "      <td>0.09546</td>\n",
       "      <td>0.09350</td>\n",
       "      <td>0.03846</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>0.07920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>1</td>\n",
       "      <td>10.820</td>\n",
       "      <td>24.21</td>\n",
       "      <td>68.89</td>\n",
       "      <td>361.6</td>\n",
       "      <td>0.08192</td>\n",
       "      <td>0.06602</td>\n",
       "      <td>0.015480</td>\n",
       "      <td>0.008160</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>...</td>\n",
       "      <td>13.030</td>\n",
       "      <td>31.45</td>\n",
       "      <td>83.90</td>\n",
       "      <td>505.6</td>\n",
       "      <td>0.12040</td>\n",
       "      <td>0.16330</td>\n",
       "      <td>0.06194</td>\n",
       "      <td>0.03264</td>\n",
       "      <td>0.3059</td>\n",
       "      <td>0.07626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>1</td>\n",
       "      <td>10.860</td>\n",
       "      <td>21.48</td>\n",
       "      <td>68.51</td>\n",
       "      <td>360.5</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.04227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1661</td>\n",
       "      <td>...</td>\n",
       "      <td>11.660</td>\n",
       "      <td>24.77</td>\n",
       "      <td>74.08</td>\n",
       "      <td>412.3</td>\n",
       "      <td>0.10010</td>\n",
       "      <td>0.07348</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.06592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>1</td>\n",
       "      <td>11.130</td>\n",
       "      <td>22.44</td>\n",
       "      <td>71.49</td>\n",
       "      <td>378.4</td>\n",
       "      <td>0.09566</td>\n",
       "      <td>0.08194</td>\n",
       "      <td>0.048240</td>\n",
       "      <td>0.022570</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020</td>\n",
       "      <td>28.26</td>\n",
       "      <td>77.80</td>\n",
       "      <td>436.6</td>\n",
       "      <td>0.10870</td>\n",
       "      <td>0.17820</td>\n",
       "      <td>0.15640</td>\n",
       "      <td>0.06413</td>\n",
       "      <td>0.3169</td>\n",
       "      <td>0.08032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>1</td>\n",
       "      <td>12.770</td>\n",
       "      <td>29.43</td>\n",
       "      <td>81.35</td>\n",
       "      <td>507.9</td>\n",
       "      <td>0.08276</td>\n",
       "      <td>0.04234</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.014990</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>...</td>\n",
       "      <td>13.870</td>\n",
       "      <td>36.00</td>\n",
       "      <td>88.10</td>\n",
       "      <td>594.7</td>\n",
       "      <td>0.12340</td>\n",
       "      <td>0.10640</td>\n",
       "      <td>0.08653</td>\n",
       "      <td>0.06498</td>\n",
       "      <td>0.2407</td>\n",
       "      <td>0.06484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>1</td>\n",
       "      <td>9.333</td>\n",
       "      <td>21.94</td>\n",
       "      <td>59.01</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.09240</td>\n",
       "      <td>0.05605</td>\n",
       "      <td>0.039960</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>0.1692</td>\n",
       "      <td>...</td>\n",
       "      <td>9.845</td>\n",
       "      <td>25.05</td>\n",
       "      <td>62.86</td>\n",
       "      <td>295.8</td>\n",
       "      <td>0.11030</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.07993</td>\n",
       "      <td>0.02564</td>\n",
       "      <td>0.2435</td>\n",
       "      <td>0.07393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>1</td>\n",
       "      <td>12.880</td>\n",
       "      <td>28.92</td>\n",
       "      <td>82.50</td>\n",
       "      <td>514.3</td>\n",
       "      <td>0.08123</td>\n",
       "      <td>0.05824</td>\n",
       "      <td>0.061950</td>\n",
       "      <td>0.023430</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>...</td>\n",
       "      <td>13.890</td>\n",
       "      <td>35.74</td>\n",
       "      <td>88.84</td>\n",
       "      <td>595.7</td>\n",
       "      <td>0.12270</td>\n",
       "      <td>0.16200</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.06493</td>\n",
       "      <td>0.2372</td>\n",
       "      <td>0.07242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>1</td>\n",
       "      <td>10.290</td>\n",
       "      <td>27.61</td>\n",
       "      <td>65.67</td>\n",
       "      <td>321.4</td>\n",
       "      <td>0.09030</td>\n",
       "      <td>0.07658</td>\n",
       "      <td>0.059990</td>\n",
       "      <td>0.027380</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>...</td>\n",
       "      <td>10.840</td>\n",
       "      <td>34.91</td>\n",
       "      <td>69.57</td>\n",
       "      <td>357.6</td>\n",
       "      <td>0.13840</td>\n",
       "      <td>0.17100</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.09127</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.08283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>1</td>\n",
       "      <td>10.160</td>\n",
       "      <td>19.59</td>\n",
       "      <td>64.73</td>\n",
       "      <td>311.7</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.07504</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>...</td>\n",
       "      <td>10.650</td>\n",
       "      <td>22.88</td>\n",
       "      <td>67.88</td>\n",
       "      <td>347.3</td>\n",
       "      <td>0.12650</td>\n",
       "      <td>0.12000</td>\n",
       "      <td>0.01005</td>\n",
       "      <td>0.02232</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.06742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>1</td>\n",
       "      <td>9.423</td>\n",
       "      <td>27.88</td>\n",
       "      <td>59.26</td>\n",
       "      <td>271.3</td>\n",
       "      <td>0.08123</td>\n",
       "      <td>0.04971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1742</td>\n",
       "      <td>...</td>\n",
       "      <td>10.490</td>\n",
       "      <td>34.24</td>\n",
       "      <td>66.50</td>\n",
       "      <td>330.6</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.07158</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>0.06969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>1</td>\n",
       "      <td>14.590</td>\n",
       "      <td>22.68</td>\n",
       "      <td>96.39</td>\n",
       "      <td>657.1</td>\n",
       "      <td>0.08473</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.037360</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>...</td>\n",
       "      <td>15.480</td>\n",
       "      <td>27.27</td>\n",
       "      <td>105.90</td>\n",
       "      <td>733.5</td>\n",
       "      <td>0.10260</td>\n",
       "      <td>0.31710</td>\n",
       "      <td>0.36620</td>\n",
       "      <td>0.11050</td>\n",
       "      <td>0.2258</td>\n",
       "      <td>0.08004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>1</td>\n",
       "      <td>11.510</td>\n",
       "      <td>23.93</td>\n",
       "      <td>74.52</td>\n",
       "      <td>403.5</td>\n",
       "      <td>0.09261</td>\n",
       "      <td>0.10210</td>\n",
       "      <td>0.111200</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>...</td>\n",
       "      <td>12.480</td>\n",
       "      <td>37.16</td>\n",
       "      <td>82.28</td>\n",
       "      <td>474.2</td>\n",
       "      <td>0.12980</td>\n",
       "      <td>0.25170</td>\n",
       "      <td>0.36300</td>\n",
       "      <td>0.09653</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.08732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>1</td>\n",
       "      <td>14.050</td>\n",
       "      <td>27.15</td>\n",
       "      <td>91.38</td>\n",
       "      <td>600.4</td>\n",
       "      <td>0.09929</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.044620</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>0.1537</td>\n",
       "      <td>...</td>\n",
       "      <td>15.300</td>\n",
       "      <td>33.17</td>\n",
       "      <td>100.20</td>\n",
       "      <td>706.7</td>\n",
       "      <td>0.12410</td>\n",
       "      <td>0.22640</td>\n",
       "      <td>0.13260</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.08321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>1</td>\n",
       "      <td>11.200</td>\n",
       "      <td>29.37</td>\n",
       "      <td>70.67</td>\n",
       "      <td>386.0</td>\n",
       "      <td>0.07449</td>\n",
       "      <td>0.03558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>...</td>\n",
       "      <td>11.920</td>\n",
       "      <td>38.30</td>\n",
       "      <td>75.19</td>\n",
       "      <td>439.6</td>\n",
       "      <td>0.09267</td>\n",
       "      <td>0.05494</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>0.05905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0</td>\n",
       "      <td>15.220</td>\n",
       "      <td>30.62</td>\n",
       "      <td>103.40</td>\n",
       "      <td>716.9</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.20870</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.094290</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>...</td>\n",
       "      <td>17.520</td>\n",
       "      <td>42.79</td>\n",
       "      <td>128.70</td>\n",
       "      <td>915.0</td>\n",
       "      <td>0.14170</td>\n",
       "      <td>0.79170</td>\n",
       "      <td>1.17000</td>\n",
       "      <td>0.23560</td>\n",
       "      <td>0.4089</td>\n",
       "      <td>0.14090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>0</td>\n",
       "      <td>20.920</td>\n",
       "      <td>25.09</td>\n",
       "      <td>143.00</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.22360</td>\n",
       "      <td>0.317400</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>...</td>\n",
       "      <td>24.290</td>\n",
       "      <td>29.41</td>\n",
       "      <td>179.10</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>0.14070</td>\n",
       "      <td>0.41860</td>\n",
       "      <td>0.65990</td>\n",
       "      <td>0.25420</td>\n",
       "      <td>0.2929</td>\n",
       "      <td>0.09873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0</td>\n",
       "      <td>21.560</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.243900</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.41070</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0</td>\n",
       "      <td>20.130</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.097910</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0</td>\n",
       "      <td>16.600</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.092510</td>\n",
       "      <td>0.053020</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.34030</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0</td>\n",
       "      <td>20.600</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.351400</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.93870</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1</td>\n",
       "      <td>7.760</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cancer  mean radius  mean texture  mean perimeter  mean area  \\\n",
       "0         0       17.990         10.38          122.80     1001.0   \n",
       "1         0       20.570         17.77          132.90     1326.0   \n",
       "2         0       19.690         21.25          130.00     1203.0   \n",
       "3         0       11.420         20.38           77.58      386.1   \n",
       "4         0       20.290         14.34          135.10     1297.0   \n",
       "5         0       12.450         15.70           82.57      477.1   \n",
       "6         0       18.250         19.98          119.60     1040.0   \n",
       "7         0       13.710         20.83           90.20      577.9   \n",
       "8         0       13.000         21.82           87.50      519.8   \n",
       "9         0       12.460         24.04           83.97      475.9   \n",
       "10        0       16.020         23.24          102.70      797.8   \n",
       "11        0       15.780         17.89          103.60      781.0   \n",
       "12        0       19.170         24.80          132.40     1123.0   \n",
       "13        0       15.850         23.95          103.70      782.7   \n",
       "14        0       13.730         22.61           93.60      578.3   \n",
       "15        0       14.540         27.54           96.73      658.8   \n",
       "16        0       14.680         20.13           94.74      684.5   \n",
       "17        0       16.130         20.68          108.10      798.8   \n",
       "18        0       19.810         22.15          130.00     1260.0   \n",
       "19        1       13.540         14.36           87.46      566.3   \n",
       "20        1       13.080         15.71           85.63      520.0   \n",
       "21        1        9.504         12.44           60.34      273.9   \n",
       "22        0       15.340         14.26          102.50      704.4   \n",
       "23        0       21.160         23.04          137.20     1404.0   \n",
       "24        0       16.650         21.38          110.00      904.6   \n",
       "25        0       17.140         16.40          116.00      912.7   \n",
       "26        0       14.580         21.53           97.41      644.8   \n",
       "27        0       18.610         20.25          122.10     1094.0   \n",
       "28        0       15.300         25.27          102.40      732.4   \n",
       "29        0       17.570         15.05          115.00      955.1   \n",
       "..      ...          ...           ...             ...        ...   \n",
       "539       1        7.691         25.44           48.34      170.4   \n",
       "540       1       11.540         14.44           74.65      402.9   \n",
       "541       1       14.470         24.99           95.81      656.4   \n",
       "542       1       14.740         25.42           94.70      668.6   \n",
       "543       1       13.210         28.06           84.88      538.4   \n",
       "544       1       13.870         20.70           89.77      584.8   \n",
       "545       1       13.620         23.23           87.19      573.2   \n",
       "546       1       10.320         16.35           65.31      324.9   \n",
       "547       1       10.260         16.58           65.85      320.8   \n",
       "548       1        9.683         19.34           61.05      285.7   \n",
       "549       1       10.820         24.21           68.89      361.6   \n",
       "550       1       10.860         21.48           68.51      360.5   \n",
       "551       1       11.130         22.44           71.49      378.4   \n",
       "552       1       12.770         29.43           81.35      507.9   \n",
       "553       1        9.333         21.94           59.01      264.0   \n",
       "554       1       12.880         28.92           82.50      514.3   \n",
       "555       1       10.290         27.61           65.67      321.4   \n",
       "556       1       10.160         19.59           64.73      311.7   \n",
       "557       1        9.423         27.88           59.26      271.3   \n",
       "558       1       14.590         22.68           96.39      657.1   \n",
       "559       1       11.510         23.93           74.52      403.5   \n",
       "560       1       14.050         27.15           91.38      600.4   \n",
       "561       1       11.200         29.37           70.67      386.0   \n",
       "562       0       15.220         30.62          103.40      716.9   \n",
       "563       0       20.920         25.09          143.00     1347.0   \n",
       "564       0       21.560         22.39          142.00     1479.0   \n",
       "565       0       20.130         28.25          131.20     1261.0   \n",
       "566       0       16.600         28.08          108.30      858.1   \n",
       "567       0       20.600         29.33          140.10     1265.0   \n",
       "568       1        7.760         24.54           47.92      181.0   \n",
       "\n",
       "     mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "0            0.11840           0.27760        0.300100             0.147100   \n",
       "1            0.08474           0.07864        0.086900             0.070170   \n",
       "2            0.10960           0.15990        0.197400             0.127900   \n",
       "3            0.14250           0.28390        0.241400             0.105200   \n",
       "4            0.10030           0.13280        0.198000             0.104300   \n",
       "5            0.12780           0.17000        0.157800             0.080890   \n",
       "6            0.09463           0.10900        0.112700             0.074000   \n",
       "7            0.11890           0.16450        0.093660             0.059850   \n",
       "8            0.12730           0.19320        0.185900             0.093530   \n",
       "9            0.11860           0.23960        0.227300             0.085430   \n",
       "10           0.08206           0.06669        0.032990             0.033230   \n",
       "11           0.09710           0.12920        0.099540             0.066060   \n",
       "12           0.09740           0.24580        0.206500             0.111800   \n",
       "13           0.08401           0.10020        0.099380             0.053640   \n",
       "14           0.11310           0.22930        0.212800             0.080250   \n",
       "15           0.11390           0.15950        0.163900             0.073640   \n",
       "16           0.09867           0.07200        0.073950             0.052590   \n",
       "17           0.11700           0.20220        0.172200             0.102800   \n",
       "18           0.09831           0.10270        0.147900             0.094980   \n",
       "19           0.09779           0.08129        0.066640             0.047810   \n",
       "20           0.10750           0.12700        0.045680             0.031100   \n",
       "21           0.10240           0.06492        0.029560             0.020760   \n",
       "22           0.10730           0.21350        0.207700             0.097560   \n",
       "23           0.09428           0.10220        0.109700             0.086320   \n",
       "24           0.11210           0.14570        0.152500             0.091700   \n",
       "25           0.11860           0.22760        0.222900             0.140100   \n",
       "26           0.10540           0.18680        0.142500             0.087830   \n",
       "27           0.09440           0.10660        0.149000             0.077310   \n",
       "28           0.10820           0.16970        0.168300             0.087510   \n",
       "29           0.09847           0.11570        0.098750             0.079530   \n",
       "..               ...               ...             ...                  ...   \n",
       "539          0.08668           0.11990        0.092520             0.013640   \n",
       "540          0.09984           0.11200        0.067370             0.025940   \n",
       "541          0.08837           0.12300        0.100900             0.038900   \n",
       "542          0.08275           0.07214        0.041050             0.030270   \n",
       "543          0.08671           0.06877        0.029870             0.032750   \n",
       "544          0.09578           0.10180        0.036880             0.023690   \n",
       "545          0.09246           0.06747        0.029740             0.024430   \n",
       "546          0.09434           0.04994        0.010120             0.005495   \n",
       "547          0.08877           0.08066        0.043580             0.024380   \n",
       "548          0.08491           0.05030        0.023370             0.009615   \n",
       "549          0.08192           0.06602        0.015480             0.008160   \n",
       "550          0.07431           0.04227        0.000000             0.000000   \n",
       "551          0.09566           0.08194        0.048240             0.022570   \n",
       "552          0.08276           0.04234        0.019970             0.014990   \n",
       "553          0.09240           0.05605        0.039960             0.012820   \n",
       "554          0.08123           0.05824        0.061950             0.023430   \n",
       "555          0.09030           0.07658        0.059990             0.027380   \n",
       "556          0.10030           0.07504        0.005025             0.011160   \n",
       "557          0.08123           0.04971        0.000000             0.000000   \n",
       "558          0.08473           0.13300        0.102900             0.037360   \n",
       "559          0.09261           0.10210        0.111200             0.041050   \n",
       "560          0.09929           0.11260        0.044620             0.043040   \n",
       "561          0.07449           0.03558        0.000000             0.000000   \n",
       "562          0.10480           0.20870        0.255000             0.094290   \n",
       "563          0.10990           0.22360        0.317400             0.147400   \n",
       "564          0.11100           0.11590        0.243900             0.138900   \n",
       "565          0.09780           0.10340        0.144000             0.097910   \n",
       "566          0.08455           0.10230        0.092510             0.053020   \n",
       "567          0.11780           0.27700        0.351400             0.152000   \n",
       "568          0.05263           0.04362        0.000000             0.000000   \n",
       "\n",
       "     mean symmetry           ...             worst radius  worst texture  \\\n",
       "0           0.2419           ...                   25.380          17.33   \n",
       "1           0.1812           ...                   24.990          23.41   \n",
       "2           0.2069           ...                   23.570          25.53   \n",
       "3           0.2597           ...                   14.910          26.50   \n",
       "4           0.1809           ...                   22.540          16.67   \n",
       "5           0.2087           ...                   15.470          23.75   \n",
       "6           0.1794           ...                   22.880          27.66   \n",
       "7           0.2196           ...                   17.060          28.14   \n",
       "8           0.2350           ...                   15.490          30.73   \n",
       "9           0.2030           ...                   15.090          40.68   \n",
       "10          0.1528           ...                   19.190          33.88   \n",
       "11          0.1842           ...                   20.420          27.28   \n",
       "12          0.2397           ...                   20.960          29.94   \n",
       "13          0.1847           ...                   16.840          27.66   \n",
       "14          0.2069           ...                   15.030          32.01   \n",
       "15          0.2303           ...                   17.460          37.13   \n",
       "16          0.1586           ...                   19.070          30.88   \n",
       "17          0.2164           ...                   20.960          31.48   \n",
       "18          0.1582           ...                   27.320          30.88   \n",
       "19          0.1885           ...                   15.110          19.26   \n",
       "20          0.1967           ...                   14.500          20.49   \n",
       "21          0.1815           ...                   10.230          15.66   \n",
       "22          0.2521           ...                   18.070          19.08   \n",
       "23          0.1769           ...                   29.170          35.59   \n",
       "24          0.1995           ...                   26.460          31.56   \n",
       "25          0.3040           ...                   22.250          21.40   \n",
       "26          0.2252           ...                   17.620          33.21   \n",
       "27          0.1697           ...                   21.310          27.26   \n",
       "28          0.1926           ...                   20.270          36.71   \n",
       "29          0.1739           ...                   20.010          19.52   \n",
       "..             ...           ...                      ...            ...   \n",
       "539         0.2037           ...                    8.678          31.89   \n",
       "540         0.1818           ...                   12.260          19.68   \n",
       "541         0.1872           ...                   16.220          31.73   \n",
       "542         0.1840           ...                   16.510          32.29   \n",
       "543         0.1628           ...                   14.370          37.17   \n",
       "544         0.1620           ...                   15.050          24.75   \n",
       "545         0.1664           ...                   15.350          29.09   \n",
       "546         0.1885           ...                   11.250          21.77   \n",
       "547         0.1669           ...                   10.830          22.04   \n",
       "548         0.1580           ...                   10.930          25.59   \n",
       "549         0.1976           ...                   13.030          31.45   \n",
       "550         0.1661           ...                   11.660          24.77   \n",
       "551         0.2030           ...                   12.020          28.26   \n",
       "552         0.1539           ...                   13.870          36.00   \n",
       "553         0.1692           ...                    9.845          25.05   \n",
       "554         0.1566           ...                   13.890          35.74   \n",
       "555         0.1593           ...                   10.840          34.91   \n",
       "556         0.1791           ...                   10.650          22.88   \n",
       "557         0.1742           ...                   10.490          34.24   \n",
       "558         0.1454           ...                   15.480          27.27   \n",
       "559         0.1388           ...                   12.480          37.16   \n",
       "560         0.1537           ...                   15.300          33.17   \n",
       "561         0.1060           ...                   11.920          38.30   \n",
       "562         0.2128           ...                   17.520          42.79   \n",
       "563         0.2149           ...                   24.290          29.41   \n",
       "564         0.1726           ...                   25.450          26.40   \n",
       "565         0.1752           ...                   23.690          38.25   \n",
       "566         0.1590           ...                   18.980          34.12   \n",
       "567         0.2397           ...                   25.740          39.42   \n",
       "568         0.1587           ...                    9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "5             103.40       741.6           0.17910            0.52490   \n",
       "6             153.20      1606.0           0.14420            0.25760   \n",
       "7             110.60       897.0           0.16540            0.36820   \n",
       "8             106.20       739.3           0.17030            0.54010   \n",
       "9              97.65       711.4           0.18530            1.05800   \n",
       "10            123.80      1150.0           0.11810            0.15510   \n",
       "11            136.50      1299.0           0.13960            0.56090   \n",
       "12            151.70      1332.0           0.10370            0.39030   \n",
       "13            112.00       876.5           0.11310            0.19240   \n",
       "14            108.80       697.7           0.16510            0.77250   \n",
       "15            124.10       943.2           0.16780            0.65770   \n",
       "16            123.40      1138.0           0.14640            0.18710   \n",
       "17            136.80      1315.0           0.17890            0.42330   \n",
       "18            186.80      2398.0           0.15120            0.31500   \n",
       "19             99.70       711.2           0.14400            0.17730   \n",
       "20             96.09       630.5           0.13120            0.27760   \n",
       "21             65.13       314.9           0.13240            0.11480   \n",
       "22            125.10       980.9           0.13900            0.59540   \n",
       "23            188.00      2615.0           0.14010            0.26000   \n",
       "24            177.00      2215.0           0.18050            0.35780   \n",
       "25            152.40      1461.0           0.15450            0.39490   \n",
       "26            122.40       896.9           0.15250            0.66430   \n",
       "27            139.90      1403.0           0.13380            0.21170   \n",
       "28            149.30      1269.0           0.16410            0.61100   \n",
       "29            134.90      1227.0           0.12550            0.28120   \n",
       "..               ...         ...               ...                ...   \n",
       "539            54.49       223.6           0.15960            0.30640   \n",
       "540            78.78       457.8           0.13450            0.21180   \n",
       "541           113.50       808.9           0.13400            0.42020   \n",
       "542           107.40       826.4           0.10600            0.13760   \n",
       "543            92.48       629.6           0.10720            0.13810   \n",
       "544            99.17       688.6           0.12640            0.20370   \n",
       "545            97.58       729.8           0.12160            0.15170   \n",
       "546            71.12       384.9           0.12850            0.08842   \n",
       "547            71.08       357.4           0.14610            0.22460   \n",
       "548            69.10       364.2           0.11990            0.09546   \n",
       "549            83.90       505.6           0.12040            0.16330   \n",
       "550            74.08       412.3           0.10010            0.07348   \n",
       "551            77.80       436.6           0.10870            0.17820   \n",
       "552            88.10       594.7           0.12340            0.10640   \n",
       "553            62.86       295.8           0.11030            0.08298   \n",
       "554            88.84       595.7           0.12270            0.16200   \n",
       "555            69.57       357.6           0.13840            0.17100   \n",
       "556            67.88       347.3           0.12650            0.12000   \n",
       "557            66.50       330.6           0.10730            0.07158   \n",
       "558           105.90       733.5           0.10260            0.31710   \n",
       "559            82.28       474.2           0.12980            0.25170   \n",
       "560           100.20       706.7           0.12410            0.22640   \n",
       "561            75.19       439.6           0.09267            0.05494   \n",
       "562           128.70       915.0           0.14170            0.79170   \n",
       "563           179.10      1819.0           0.14070            0.41860   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0            0.71190               0.26540          0.4601   \n",
       "1            0.24160               0.18600          0.2750   \n",
       "2            0.45040               0.24300          0.3613   \n",
       "3            0.68690               0.25750          0.6638   \n",
       "4            0.40000               0.16250          0.2364   \n",
       "5            0.53550               0.17410          0.3985   \n",
       "6            0.37840               0.19320          0.3063   \n",
       "7            0.26780               0.15560          0.3196   \n",
       "8            0.53900               0.20600          0.4378   \n",
       "9            1.10500               0.22100          0.4366   \n",
       "10           0.14590               0.09975          0.2948   \n",
       "11           0.39650               0.18100          0.3792   \n",
       "12           0.36390               0.17670          0.3176   \n",
       "13           0.23220               0.11190          0.2809   \n",
       "14           0.69430               0.22080          0.3596   \n",
       "15           0.70260               0.17120          0.4218   \n",
       "16           0.29140               0.16090          0.3029   \n",
       "17           0.47840               0.20730          0.3706   \n",
       "18           0.53720               0.23880          0.2768   \n",
       "19           0.23900               0.12880          0.2977   \n",
       "20           0.18900               0.07283          0.3184   \n",
       "21           0.08867               0.06227          0.2450   \n",
       "22           0.63050               0.23930          0.4667   \n",
       "23           0.31550               0.20090          0.2822   \n",
       "24           0.46950               0.20950          0.3613   \n",
       "25           0.38530               0.25500          0.4066   \n",
       "26           0.55390               0.27010          0.4264   \n",
       "27           0.34460               0.14900          0.2341   \n",
       "28           0.63350               0.20240          0.4027   \n",
       "29           0.24890               0.14560          0.2756   \n",
       "..               ...                   ...             ...   \n",
       "539          0.33930               0.05000          0.2790   \n",
       "540          0.17970               0.06918          0.2329   \n",
       "541          0.40400               0.12050          0.3187   \n",
       "542          0.16110               0.10950          0.2722   \n",
       "543          0.10620               0.07958          0.2473   \n",
       "544          0.13770               0.06845          0.2249   \n",
       "545          0.10490               0.07174          0.2642   \n",
       "546          0.04384               0.02381          0.2681   \n",
       "547          0.17830               0.08333          0.2691   \n",
       "548          0.09350               0.03846          0.2552   \n",
       "549          0.06194               0.03264          0.3059   \n",
       "550          0.00000               0.00000          0.2458   \n",
       "551          0.15640               0.06413          0.3169   \n",
       "552          0.08653               0.06498          0.2407   \n",
       "553          0.07993               0.02564          0.2435   \n",
       "554          0.24390               0.06493          0.2372   \n",
       "555          0.20000               0.09127          0.2226   \n",
       "556          0.01005               0.02232          0.2262   \n",
       "557          0.00000               0.00000          0.2475   \n",
       "558          0.36620               0.11050          0.2258   \n",
       "559          0.36300               0.09653          0.2112   \n",
       "560          0.13260               0.10480          0.2250   \n",
       "561          0.00000               0.00000          0.1566   \n",
       "562          1.17000               0.23560          0.4089   \n",
       "563          0.65990               0.25420          0.2929   \n",
       "564          0.41070               0.22160          0.2060   \n",
       "565          0.32150               0.16280          0.2572   \n",
       "566          0.34030               0.14180          0.2218   \n",
       "567          0.93870               0.26500          0.4087   \n",
       "568          0.00000               0.00000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "5                    0.12440  \n",
       "6                    0.08368  \n",
       "7                    0.11510  \n",
       "8                    0.10720  \n",
       "9                    0.20750  \n",
       "10                   0.08452  \n",
       "11                   0.10480  \n",
       "12                   0.10230  \n",
       "13                   0.06287  \n",
       "14                   0.14310  \n",
       "15                   0.13410  \n",
       "16                   0.08216  \n",
       "17                   0.11420  \n",
       "18                   0.07615  \n",
       "19                   0.07259  \n",
       "20                   0.08183  \n",
       "21                   0.07773  \n",
       "22                   0.09946  \n",
       "23                   0.07526  \n",
       "24                   0.09564  \n",
       "25                   0.10590  \n",
       "26                   0.12750  \n",
       "27                   0.07421  \n",
       "28                   0.09876  \n",
       "29                   0.07919  \n",
       "..                       ...  \n",
       "539                  0.10660  \n",
       "540                  0.08134  \n",
       "541                  0.10230  \n",
       "542                  0.06956  \n",
       "543                  0.06443  \n",
       "544                  0.08492  \n",
       "545                  0.06953  \n",
       "546                  0.07399  \n",
       "547                  0.09479  \n",
       "548                  0.07920  \n",
       "549                  0.07626  \n",
       "550                  0.06592  \n",
       "551                  0.08032  \n",
       "552                  0.06484  \n",
       "553                  0.07393  \n",
       "554                  0.07242  \n",
       "555                  0.08283  \n",
       "556                  0.06742  \n",
       "557                  0.06969  \n",
       "558                  0.08004  \n",
       "559                  0.08732  \n",
       "560                  0.08321  \n",
       "561                  0.05905  \n",
       "562                  0.14090  \n",
       "563                  0.09873  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target = pd.DataFrame(cancer['target'],columns=['Cancer'])\n",
    "pd.concat([df_target, df_feat], axis=1, join_axes=[df_target.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.JointGrid at 0x13786c160>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAGpCAYAAADGJ5LWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFJhERMRVFJhERMRVFJhERMRV/j+sFDnb60GxzQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13786c3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.jointplot(x=\"worst area\", y=\"mean radius\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HirokiSunagawa/anaconda/lib/python3.5/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cancer</th>\n",
       "      <th>area error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>...</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst texture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.627417</td>\n",
       "      <td>40.337079</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>...</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>25.677223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.483918</td>\n",
       "      <td>45.491006</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.030186</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>...</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>6.146258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.802000</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>12.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>542.200000</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>0.052790</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>0.029840</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>...</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>49.540000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Cancer  area error  compactness error  concave points error  \\\n",
       "count  569.000000  569.000000         569.000000            569.000000   \n",
       "mean     0.627417   40.337079           0.025478              0.011796   \n",
       "std      0.483918   45.491006           0.017908              0.006170   \n",
       "min      0.000000    6.802000           0.002252              0.000000   \n",
       "25%           NaN         NaN                NaN                   NaN   \n",
       "50%           NaN         NaN                NaN                   NaN   \n",
       "75%           NaN         NaN                NaN                   NaN   \n",
       "max      1.000000  542.200000           0.135400              0.052790   \n",
       "\n",
       "       concavity error  fractal dimension error    mean area  \\\n",
       "count       569.000000               569.000000   569.000000   \n",
       "mean          0.031894                 0.003795   654.889104   \n",
       "std           0.030186                 0.002646   351.914129   \n",
       "min           0.000000                 0.000895   143.500000   \n",
       "25%                NaN                      NaN          NaN   \n",
       "50%                NaN                      NaN          NaN   \n",
       "75%                NaN                      NaN          NaN   \n",
       "max           0.396000                 0.029840  2501.000000   \n",
       "\n",
       "       mean compactness  mean concave points  mean concavity      ...        \\\n",
       "count        569.000000           569.000000      569.000000      ...         \n",
       "mean           0.104341             0.048919        0.088799      ...         \n",
       "std            0.052813             0.038803        0.079720      ...         \n",
       "min            0.019380             0.000000        0.000000      ...         \n",
       "25%                 NaN                  NaN             NaN      ...         \n",
       "50%                 NaN                  NaN             NaN      ...         \n",
       "75%                 NaN                  NaN             NaN      ...         \n",
       "max            0.345400             0.201200        0.426800      ...         \n",
       "\n",
       "        worst area  worst compactness  worst concave points  worst concavity  \\\n",
       "count   569.000000         569.000000            569.000000       569.000000   \n",
       "mean    880.583128           0.254265              0.114606         0.272188   \n",
       "std     569.356993           0.157336              0.065732         0.208624   \n",
       "min     185.200000           0.027290              0.000000         0.000000   \n",
       "25%            NaN                NaN                   NaN              NaN   \n",
       "50%            NaN                NaN                   NaN              NaN   \n",
       "75%            NaN                NaN                   NaN              NaN   \n",
       "max    4254.000000           1.058000              0.291000         1.252000   \n",
       "\n",
       "       worst fractal dimension  worst perimeter  worst radius  \\\n",
       "count               569.000000       569.000000    569.000000   \n",
       "mean                  0.083946       107.261213     16.269190   \n",
       "std                   0.018061        33.602542      4.833242   \n",
       "min                   0.055040        50.410000      7.930000   \n",
       "25%                        NaN              NaN           NaN   \n",
       "50%                        NaN              NaN           NaN   \n",
       "75%                        NaN              NaN           NaN   \n",
       "max                   0.207500       251.200000     36.040000   \n",
       "\n",
       "       worst smoothness  worst symmetry  worst texture  \n",
       "count        569.000000      569.000000     569.000000  \n",
       "mean           0.132369        0.290076      25.677223  \n",
       "std            0.022832        0.061867       6.146258  \n",
       "min            0.071170        0.156500      12.020000  \n",
       "25%                 NaN             NaN            NaN  \n",
       "50%                 NaN             NaN            NaN  \n",
       "75%                 NaN             NaN            NaN  \n",
       "max            0.222600        0.663800      49.540000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually check out the dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll skip the Data Viz part for this lecture since there are so many features that are hard to interpret if you don't have domain knowledge of cancer or tumor cells. In your project you will have more to visualize for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_feat, np.ravel(df_target), test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and Evaluations\n",
    "\n",
    "Now let's predict using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  66]\n",
      " [  0 105]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        66\n",
      "          1       0.61      1.00      0.76       105\n",
      "\n",
      "avg / total       0.38      0.61      0.47       171\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marci/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah! Notice that we are classifying everything into a single class! This means our model needs to have it parameters adjusted (it may also help to normalize the data).\n",
    "\n",
    "We can search for parameters using a GridSearch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch\n",
    "\n",
    "Finding the right parameters (like what C or gamma values to use) is a tricky task! But luckily, we can be a little lazy and just try a bunch of combinations and see what works best! This idea of creating a 'grid' of parameters and just trying out all the possible combinations is called a Gridsearch, this method is common enough that Scikit-learn has this functionality built in with GridSearchCV! The CV stands for cross-validation which is the\n",
    "\n",
    "GridSearchCV takes a dictionary that describes the parameters that should be tried and a model to train. The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a meta-estimator. It takes an estimator like SVC, and creates a new estimator, that behaves exactly the same - in this case, like a classifier. You should add refit=True and choose verbose to whatever number you want, higher the number, the more verbose (verbose just means the text output describing the process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What fit does is a bit more involved then usual. First, it runs the same loop with cross-validation, to find the best parameter combination. Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] C=0.1, kernel=rbf, gamma=1 ......................................\n",
      "[CV] ....... C=0.1, kernel=rbf, gamma=1, score=0.631579, total=   0.0s\n",
      "[CV] C=0.1, kernel=rbf, gamma=1 ......................................\n",
      "[CV] ....... C=0.1, kernel=rbf, gamma=1, score=0.631579, total=   0.0s\n",
      "[CV] C=0.1, kernel=rbf, gamma=1 ......................................\n",
      "[CV] ....... C=0.1, kernel=rbf, gamma=1, score=0.636364, total=   0.0s\n",
      "[CV] C=0.1, kernel=rbf, gamma=0.1 ....................................\n",
      "[CV] ..... C=0.1, kernel=rbf, gamma=0.1, score=0.631579, total=   0.0s\n",
      "[CV] C=0.1, kernel=rbf, gamma=0.1 ....................................\n",
      "[CV] ..... C=0.1, kernel=rbf, gamma=0.1, score=0.631579, total=   0.0s\n",
      "[CV] C=0.1, kernel=rbf, gamma=0.1 ....................................\n",
      "[CV] ..... C=0.1, kernel=rbf, gamma=0.1, score=0.636364, total=   0.0s\n",
      "[CV] C=0.1, kernel=rbf, gamma=0.01 ...................................\n",
      "[CV] .... C=0.1, kernel=rbf, gamma=0.01, score=0.631579, total=   0.0s\n",
      "[CV] C=0.1, kernel=rbf, gamma=0.01 ...................................\n",
      "[CV] .... C=0.1, kernel=rbf, gamma=0.01, score=0.631579, total=   0.0s\n",
      "[CV] C=0.1, kernel=rbf, gamma=0.01 ...................................\n",
      "[CV] .... C=0.1, kernel=rbf, gamma=0.01, score=0.636364, total=   0.0s\n",
      "[CV] C=0.1, kernel=rbf, gamma=0.001 ..................................\n",
      "[CV] ... C=0.1, kernel=rbf, gamma=0.001, score=0.631579, total=   0.0s\n",
      "[CV] C=0.1, kernel=rbf, gamma=0.001 ..................................\n",
      "[CV] ... C=0.1, kernel=rbf, gamma=0.001, score=0.631579, total=   0.0s\n",
      "[CV] C=0.1, kernel=rbf, gamma=0.001 ..................................\n",
      "[CV] ... C=0.1, kernel=rbf, gamma=0.001, score=0.636364, total=   0.0s\n",
      "[CV] C=0.1, kernel=rbf, gamma=0.0001 .................................\n",
      "[CV] .. C=0.1, kernel=rbf, gamma=0.0001, score=0.902256, total=   0.0s\n",
      "[CV] C=0.1, kernel=rbf, gamma=0.0001 .................................\n",
      "[CV] .. C=0.1, kernel=rbf, gamma=0.0001, score=0.962406, total=   0.0s\n",
      "[CV] C=0.1, kernel=rbf, gamma=0.0001 .................................\n",
      "[CV] .. C=0.1, kernel=rbf, gamma=0.0001, score=0.916667, total=   0.0s\n",
      "[CV] C=1, kernel=rbf, gamma=1 ........................................\n",
      "[CV] ......... C=1, kernel=rbf, gamma=1, score=0.631579, total=   0.0s\n",
      "[CV] C=1, kernel=rbf, gamma=1 ........................................\n",
      "[CV] ......... C=1, kernel=rbf, gamma=1, score=0.631579, total=   0.0s\n",
      "[CV] C=1, kernel=rbf, gamma=1 ........................................\n",
      "[CV] ......... C=1, kernel=rbf, gamma=1, score=0.636364, total=   0.0s\n",
      "[CV] C=1, kernel=rbf, gamma=0.1 ......................................\n",
      "[CV] ....... C=1, kernel=rbf, gamma=0.1, score=0.631579, total=   0.0s\n",
      "[CV] C=1, kernel=rbf, gamma=0.1 ......................................\n",
      "[CV] ....... C=1, kernel=rbf, gamma=0.1, score=0.631579, total=   0.0s\n",
      "[CV] C=1, kernel=rbf, gamma=0.1 ......................................\n",
      "[CV] ....... C=1, kernel=rbf, gamma=0.1, score=0.636364, total=   0.0s\n",
      "[CV] C=1, kernel=rbf, gamma=0.01 .....................................\n",
      "[CV] ...... C=1, kernel=rbf, gamma=0.01, score=0.631579, total=   0.0s\n",
      "[CV] C=1, kernel=rbf, gamma=0.01 .....................................\n",
      "[CV] ...... C=1, kernel=rbf, gamma=0.01, score=0.631579, total=   0.0s\n",
      "[CV] C=1, kernel=rbf, gamma=0.01 .....................................\n",
      "[CV] ...... C=1, kernel=rbf, gamma=0.01, score=0.636364, total=   0.0s\n",
      "[CV] C=1, kernel=rbf, gamma=0.001 ....................................\n",
      "[CV] ..... C=1, kernel=rbf, gamma=0.001, score=0.902256, total=   0.0s\n",
      "[CV] C=1, kernel=rbf, gamma=0.001 ....................................\n",
      "[CV] ..... C=1, kernel=rbf, gamma=0.001, score=0.939850, total=   0.0s\n",
      "[CV] C=1, kernel=rbf, gamma=0.001 ....................................\n",
      "[CV] ..... C=1, kernel=rbf, gamma=0.001, score=0.954545, total=   0.0s\n",
      "[CV] C=1, kernel=rbf, gamma=0.0001 ...................................\n",
      "[CV] .... C=1, kernel=rbf, gamma=0.0001, score=0.939850, total=   0.0s\n",
      "[CV] C=1, kernel=rbf, gamma=0.0001 ...................................\n",
      "[CV] .... C=1, kernel=rbf, gamma=0.0001, score=0.969925, total=   0.0s\n",
      "[CV] C=1, kernel=rbf, gamma=0.0001 ...................................\n",
      "[CV] .... C=1, kernel=rbf, gamma=0.0001, score=0.946970, total=   0.0s\n",
      "[CV] C=10, kernel=rbf, gamma=1 .......................................\n",
      "[CV] ........ C=10, kernel=rbf, gamma=1, score=0.631579, total=   0.0s\n",
      "[CV] C=10, kernel=rbf, gamma=1 .......................................\n",
      "[CV] ........ C=10, kernel=rbf, gamma=1, score=0.631579, total=   0.0s\n",
      "[CV] C=10, kernel=rbf, gamma=1 .......................................\n",
      "[CV] ........ C=10, kernel=rbf, gamma=1, score=0.636364, total=   0.0s\n",
      "[CV] C=10, kernel=rbf, gamma=0.1 .....................................\n",
      "[CV] ...... C=10, kernel=rbf, gamma=0.1, score=0.631579, total=   0.0s\n",
      "[CV] C=10, kernel=rbf, gamma=0.1 .....................................\n",
      "[CV] ...... C=10, kernel=rbf, gamma=0.1, score=0.631579, total=   0.0s\n",
      "[CV] C=10, kernel=rbf, gamma=0.1 .....................................\n",
      "[CV] ...... C=10, kernel=rbf, gamma=0.1, score=0.636364, total=   0.0s\n",
      "[CV] C=10, kernel=rbf, gamma=0.01 ....................................\n",
      "[CV] ..... C=10, kernel=rbf, gamma=0.01, score=0.631579, total=   0.0s\n",
      "[CV] C=10, kernel=rbf, gamma=0.01 ....................................\n",
      "[CV] ..... C=10, kernel=rbf, gamma=0.01, score=0.631579, total=   0.0s\n",
      "[CV] C=10, kernel=rbf, gamma=0.01 ....................................\n",
      "[CV] ..... C=10, kernel=rbf, gamma=0.01, score=0.636364, total=   0.0s\n",
      "[CV] C=10, kernel=rbf, gamma=0.001 ...................................\n",
      "[CV] .... C=10, kernel=rbf, gamma=0.001, score=0.894737, total=   0.0s\n",
      "[CV] C=10, kernel=rbf, gamma=0.001 ...................................\n",
      "[CV] .... C=10, kernel=rbf, gamma=0.001, score=0.932331, total=   0.0s\n",
      "[CV] C=10, kernel=rbf, gamma=0.001 ...................................\n",
      "[CV] .... C=10, kernel=rbf, gamma=0.001, score=0.916667, total=   0.0s\n",
      "[CV] C=10, kernel=rbf, gamma=0.0001 ..................................\n",
      "[CV] ... C=10, kernel=rbf, gamma=0.0001, score=0.932331, total=   0.0s\n",
      "[CV] C=10, kernel=rbf, gamma=0.0001 ..................................\n",
      "[CV] ... C=10, kernel=rbf, gamma=0.0001, score=0.969925, total=   0.0s\n",
      "[CV] C=10, kernel=rbf, gamma=0.0001 ..................................\n",
      "[CV] ... C=10, kernel=rbf, gamma=0.0001, score=0.962121, total=   0.0s\n",
      "[CV] C=100, kernel=rbf, gamma=1 ......................................\n",
      "[CV] ....... C=100, kernel=rbf, gamma=1, score=0.631579, total=   0.0s\n",
      "[CV] C=100, kernel=rbf, gamma=1 ......................................\n",
      "[CV] ....... C=100, kernel=rbf, gamma=1, score=0.631579, total=   0.0s\n",
      "[CV] C=100, kernel=rbf, gamma=1 ......................................\n",
      "[CV] ....... C=100, kernel=rbf, gamma=1, score=0.636364, total=   0.0s\n",
      "[CV] C=100, kernel=rbf, gamma=0.1 ....................................\n",
      "[CV] ..... C=100, kernel=rbf, gamma=0.1, score=0.631579, total=   0.0s\n",
      "[CV] C=100, kernel=rbf, gamma=0.1 ....................................\n",
      "[CV] ..... C=100, kernel=rbf, gamma=0.1, score=0.631579, total=   0.0s\n",
      "[CV] C=100, kernel=rbf, gamma=0.1 ....................................\n",
      "[CV] ..... C=100, kernel=rbf, gamma=0.1, score=0.636364, total=   0.0s\n",
      "[CV] C=100, kernel=rbf, gamma=0.01 ...................................\n",
      "[CV] .... C=100, kernel=rbf, gamma=0.01, score=0.631579, total=   0.0s\n",
      "[CV] C=100, kernel=rbf, gamma=0.01 ...................................\n",
      "[CV] .... C=100, kernel=rbf, gamma=0.01, score=0.631579, total=   0.0s\n",
      "[CV] C=100, kernel=rbf, gamma=0.01 ...................................\n",
      "[CV] .... C=100, kernel=rbf, gamma=0.01, score=0.636364, total=   0.0s\n",
      "[CV] C=100, kernel=rbf, gamma=0.001 ..................................\n",
      "[CV] ... C=100, kernel=rbf, gamma=0.001, score=0.894737, total=   0.0s\n",
      "[CV] C=100, kernel=rbf, gamma=0.001 ..................................\n",
      "[CV] ... C=100, kernel=rbf, gamma=0.001, score=0.932331, total=   0.0s\n",
      "[CV] C=100, kernel=rbf, gamma=0.001 ..................................\n",
      "[CV] ... C=100, kernel=rbf, gamma=0.001, score=0.916667, total=   0.0s\n",
      "[CV] C=100, kernel=rbf, gamma=0.0001 .................................\n",
      "[CV] .. C=100, kernel=rbf, gamma=0.0001, score=0.917293, total=   0.0s\n",
      "[CV] C=100, kernel=rbf, gamma=0.0001 .................................\n",
      "[CV] .. C=100, kernel=rbf, gamma=0.0001, score=0.977444, total=   0.0s\n",
      "[CV] C=100, kernel=rbf, gamma=0.0001 .................................\n",
      "[CV] .. C=100, kernel=rbf, gamma=0.0001, score=0.939394, total=   0.0s\n",
      "[CV] C=1000, kernel=rbf, gamma=1 .....................................\n",
      "[CV] ...... C=1000, kernel=rbf, gamma=1, score=0.631579, total=   0.0s\n",
      "[CV] C=1000, kernel=rbf, gamma=1 .....................................\n",
      "[CV] ...... C=1000, kernel=rbf, gamma=1, score=0.631579, total=   0.0s\n",
      "[CV] C=1000, kernel=rbf, gamma=1 .....................................\n",
      "[CV] ...... C=1000, kernel=rbf, gamma=1, score=0.636364, total=   0.0s\n",
      "[CV] C=1000, kernel=rbf, gamma=0.1 ...................................\n",
      "[CV] .... C=1000, kernel=rbf, gamma=0.1, score=0.631579, total=   0.0s\n",
      "[CV] C=1000, kernel=rbf, gamma=0.1 ...................................\n",
      "[CV] .... C=1000, kernel=rbf, gamma=0.1, score=0.631579, total=   0.0s\n",
      "[CV] C=1000, kernel=rbf, gamma=0.1 ...................................\n",
      "[CV] .... C=1000, kernel=rbf, gamma=0.1, score=0.636364, total=   0.0s\n",
      "[CV] C=1000, kernel=rbf, gamma=0.01 ..................................\n",
      "[CV] ... C=1000, kernel=rbf, gamma=0.01, score=0.631579, total=   0.0s\n",
      "[CV] C=1000, kernel=rbf, gamma=0.01 ..................................\n",
      "[CV] ... C=1000, kernel=rbf, gamma=0.01, score=0.631579, total=   0.0s\n",
      "[CV] C=1000, kernel=rbf, gamma=0.01 ..................................\n",
      "[CV] ... C=1000, kernel=rbf, gamma=0.01, score=0.636364, total=   0.0s\n",
      "[CV] C=1000, kernel=rbf, gamma=0.001 .................................\n",
      "[CV] .. C=1000, kernel=rbf, gamma=0.001, score=0.894737, total=   0.0s\n",
      "[CV] C=1000, kernel=rbf, gamma=0.001 .................................\n",
      "[CV] .. C=1000, kernel=rbf, gamma=0.001, score=0.932331, total=   0.0s\n",
      "[CV] C=1000, kernel=rbf, gamma=0.001 .................................\n",
      "[CV] .. C=1000, kernel=rbf, gamma=0.001, score=0.916667, total=   0.0s\n",
      "[CV] C=1000, kernel=rbf, gamma=0.0001 ................................\n",
      "[CV] . C=1000, kernel=rbf, gamma=0.0001, score=0.909774, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=1000, kernel=rbf, gamma=0.0001 ................................\n",
      "[CV] . C=1000, kernel=rbf, gamma=0.0001, score=0.969925, total=   0.0s\n",
      "[CV] C=1000, kernel=rbf, gamma=0.0001 ................................\n",
      "[CV] . C=1000, kernel=rbf, gamma=0.0001, score=0.931818, total=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.1, 1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# May take awhile!\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the best parameters found by GridSearchCV in the best_params_ attribute, and the best estimator in the best\\_estimator_ attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can re-run predictions on this grid object just like you would with a normal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 60   6]\n",
      " [  3 102]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.91      0.93        66\n",
      "          1       0.94      0.97      0.96       105\n",
      "\n",
      "avg / total       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
